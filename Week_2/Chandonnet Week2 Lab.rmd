---
title: "Week 2 Exercises"
author: "Ray Chandonnet"
date: "November 5, 2022"
output: pdf_document
---

Please complete all exercises below. You may use stringr, lubridate, or the forcats library. 
```{r}
#add libraries
library(stringr)
library(forcats)
library(lubridate)
```

# Exercise 1
Read the sales_pipe.txt file into an R data frame as sales. 



```{r}

# Given the challenges of using the original sales_pipe.txt file on a mac, I
# created a different version using UTF-16LE which I called sales_pipe_mac.txt.  That
# alternative sample file is in my Github if you want to review it. This successfuly reads
# in using read_delim with the right file encoding specified. Doing this allowed me to still
# do exercises 2 & 3, whereas if I had imported the CSV file or the the XLSX file, the first
# column name was already fixed and the dates formatted properly in the source file.  For
# some reason, when I read in this file there is an extra column at the end with blank
# values and column header "X", so my code deletes that last column

sales <- read.delim(file="Data/sales_pipe_mac.txt",
                    stringsAsFactors=FALSE,
                    fileEncoding = "UTF-16LE",
                    header=TRUE,
                    sep="|",
                    fill=TRUE)

# Below I show the first row in Sales to show the phantom last column "X"
sales[1,]
length(sales)

# This code finds the last column and deletes it
length(sales)
sales <- sales[,-length(sales)]
length(sales)
 
# Showing that that column is now gone
sales[1,]
```

# Exercise 2
You can extract a vector of columns names from a data frame using the colnames() function. Notice the first column has some odd characters. Change the column name for the FIRST column in the sales date frame to Row.ID. 

**Note: You will need to assign the first element of colnames to a single character.**.  

Ray Note:  I must confess I don't know what the above Note means - it seems I can successfully just rename the first element in the colnames() vector as per below

```{r}
colnames(sales)[1] <- "Row.ID"
sales[1,]
```

# Exercise 3
Convert both Order.ID and Order.Date to date vectors within the sales data frame. What is the number of days between the most recent order and the oldest order?
How many years is that?
How many weeks?

**Note: Use lubridate**

```{r}
# First convert both those vectors to dates using the mdy function in lubridate.  Note that
# I am converting Order.Date and Ship. Date, not Order.ID and Order.Date

sales$Order.Date <- lubridate::mdy(sales$Order.Date)
sales$Ship.Date <- lubridate::mdy(sales$Ship.Date)

most_recent <- max(sales$Order.Date)  #Find the most recent order date
most_recent
earliest <- min(sales$Order.Date)  #Find the oldest order date
earliest

# To calculate elapsed days we can use the difftime base function in R. Since the difftime
# function returns the result in a "difftime" object, I also convert that object to numeric
# in case I want to do some math with it.  

elapsed_days_difftime <- difftime(most_recent, earliest, units = "days") #calc elapsed days
#                                                                         as difftime object
elapsed_days_difftime
elapsed_days <- as.numeric(elapsed_days_difftime) #convert to numeric
elapsed_days

# Now I use the time_length function of lubridate to calculate elapsed years and months. 
# Cannot use the base difftime function for this and specify "years" or "months" as unit
# because months and years are not of standard length

elapsed_years <- lubridate::time_length(elapsed_days_difftime,"years")
elapsed_years
elapsed_months <- lubridate::time_length(elapsed_days_difftime,"months")
elapsed_months
```


# Exercise 4
What is the average number of days it takes to ship an order?

```{r}
# I do this by first creating a new vector "shipping_days" that calculates the elapsed days
# between shipping date and order date, in numeric form, and then calculating the mean of
# that vector.  Note I am printing out the first few rows/columns of the sales data frame
# and the first few rows of the shipping_days vector to prove it works

# create vector of shipping days
shipping_days <- as.numeric(difftime(sales$Ship.Date,sales$Order.Date,units = "days")) 
sales[1:3,1:4]
shipping_days[1:3]
shipping_days_avg <- mean(shipping_days)
cat("Average # of days to ship :", shipping_days_avg)
```


# Exercise 5
How many customers have the first name Bill?
You will need to split the customer name into first and last name segments and then use a regular expression to match the first name bill. Use the length() function to determine the number of customers with the first name Bill in the sales data. 

```{r}
# So I can do this a lot of different ways, and I can also interpret the question a couple
# of different ways.  The first way to interpret the question is to ask literally "How many
# rows contain the first name Bill in Customer.Name".  The second is more subtle, asking
# "how many of our customers are named Bill".  I imagine what you wanted was the first, but
# I decided to also see if I could figure out how to do the second interpretation, which is
# to find the number of UNIQUE customers with first name Bill.

# Method 1 - Finding # of rows where customer first name is Bill by splitting the customer
# name in two.  I like this method if you want to retain a table with subset of matching
# customers

# split first from last (I turn it into a data frame rather than the default matrix output
# for the str_split_fixed function in stringr)
names_frame <- as.data.frame(stringr::str_split_fixed(sales$Customer.Name," ",2)) 
colnames(names_frame)=c("First.Name","Last.Name") # assign column names for easier notation
names_frame[1:8,]  #show the first few rows to prove it worked
first_name_is_Bill <- names_frame$First.Name == "Bill" #create boolean vector of matches
all_the_Bills_method1 <- names_frame[first_name_is_Bill,] #subset the data frame
all_the_Bills_method1

# One comment / question here:  I also could do this subsetting in one line of code like:
# all_the_Bills_method1 <- names_frame[names_frame$First.Name == "Bill",]
# I would be curious to know which you prefer as a professional.   I usually like to make my
# code really readable, so i break out complex operations into their separate components.  
# But it also makes my code longer, and I suppose I may be using up more memory by
# explicitly storing the booleans as a vector variable as opposed to passing them as an
# argument to the slicing operation...thoughts?

numBills_method1 <- length(all_the_Bills_method1$First.Name) #Count them
cat("Using Method 1, we identified", numBills_method1,"rows with first name='Bill'")

#
# Method 2 - Finding # of rows where customer first name is Bill without splitting the
# customer name in two, by looking for all Customer.Name that start with "Bill ".  I like
# this method if you just want the answer, because it's more efficient

# create vector of Booleans where first five characters of Customer.Name are "Bill "  ; 
# Note I include the space at the end to avoid accidentally getting first names like Billy,
# Billilyn, etc
first_five_matches_Bill <- stringr::str_starts(sales$Customer.Name,"Bill ") 
all_the_Bills_method2 <- sales$Customer.Name[first_five_matches_Bill] #Subset table matches 
numBills_method2 <- length(all_the_Bills_method2) #Count them
cat("Using Method 2, we identified", numBills_method2,"rows with first name='Bill'")

#
# Method 3 - In this "bonus" answer, I identify and count all the UNIQUE customers named
# Bill, so I am answering a different question, really "How many of our customers are named
# Bill"  (If there are two different people both named Bill Jones this wouldn't work without
# a unique customer identifier like an SSN to go along with it)

unique_customer_names <- unique(names_frame)  #extract unique customer names from my
#                                              previously-split table
cat("There are",length(unique_customer_names$First.Name),"unique customer names in the table")
# subset thelist to just the "Bills"
Unique_Bills <- unique_customer_names[unique_customer_names$First.Name=='Bill',] 
Unique_Bills
numBills_method3 <- length(Unique_Bills$First.Name) #count them
cat(numBills_method3,"of those customers have the first name 'Bill'")
```

# Exercise 6
How many mentions of the word 'table' are there in the Product.Name column? 
**Note you can do this in one line of code**

```{r}
# OK so this function gives me the number of times the string "table" appears, IF that's
# what you wanted
table_mentions1 = sum(stringr::str_count(sales$Product.Name,"table")) 
table_mentions1

# This gave us 240 instances of the string "table"  However I see several problems with
# this in a real-world application.  First off, if you're looking for the total sales of
# tables, you don't care whether "table" is capitalized or not.  You want to know how many
# tables you sold.  Since str_count is case sensitive, you would need to adjust for that by
# making everything the same case

table_mentions2 = sum(stringr::str_count(str_to_lower(sales$Product.Name),"table")) 
table_mentions2

# That gives us 604 instances of the string "table".  But wait....this includes instances
# where the string "table" isn't a full word, but is embedded in a word like "portable",
# "vegetable" and the like, which may not be what we want.  We may want to look for the WORD
# table.  In this case, we may want to take advantage of R's abilty to include special
# characters in a search string, in this case, using the special character "\\b" which in a
# regexp defines a word boundary.  So we can bound the word "table" with this boundary and
# end up just finding whole word matches for "table", ignoring case, like this:

searchstring <- "\\btable\\b"
table_mentions3 = sum(stringr::str_count(str_to_lower(sales$Product.Name),searchstring)) 
table_mentions3

# That gives me 230 instances of the WORD table in the product name.  From a business
# perspective, this is probably the closest I can get with this data to answering the
# question "How many tables have we sold".  (A minor flaw in this approach is that if a
# Product.Name contains the word "table" more than once I will over-count. I could solve
# for that too but then I'd be even more off on a tangent.)

# Sorry if this was too long but I feel it's really important to understand what the actual
# business or scientific question is being asked and make sure your code answers that really
# precisely!!
```

# Exercise 7
Create a table of counts for each state in the sales data. The counts table should be ordered alphabetically from A to Z. 

```{r}
state_count_table <- aggregate(sales$Row.ID, by=list(sales$State), FUN = length)
colnames(state_count_table) <- c("State","Num.Sales")
state_count_table <- state_count_table[order(state_count_table$State,decreasing = FALSE),]
state_count_table  #sort the table
```

# Exercise 8
Create an alphabetically ordered barplot for each sales Category in the State of Texas. 

```{r}

# Since the instructions don't specificy how to aggregate the data to be plotted, I chose
# to simply count the total # of sales in each category, similar to Exercise 7.   
texas_sales <- sales[sales$State=='Texas',] #extract Texas sales into new table
texas_sales_by_category <- aggregate(texas_sales$Row.ID,
                                     by=list(texas_sales$Category),
                                     FUN = length) #Aggregate by category
colnames(texas_sales_by_category) <- c("Category","Num.Sales") #assign column names
texas_sales_by_category <- texas_sales_by_category[order(texas_sales_by_category$Category,
                                                         decreasing = FALSE),] #sort
barplot(texas_sales_by_category$Num.Sales,
        names = texas_sales_by_category$Category,
        legend = "Sales by Category - Texas",
        xlab ="Product Category",
        ylab = "Total Sales Volume (Units)") # plot

```

# Exercise 9
Find the average profit by region.
**Note: You will need to use the aggregate() function to do this. To understand how the function works type ?aggregate in the console.**

```{r}

# Aggregate profits by region using mean function, and assign column names
profits_by_region <- setNames(aggregate(sales$Profit,
                                        by=list(sales$Region),
                                        FUN = mean),
                              c("Region","Avg.Profit")) 

# Sort results descending by Avg.Proft, for better presentation
profits_by_region <- profits_by_region[order(profits_by_region$Avg.Profit,
                                             decreasing = TRUE),]
profits_by_region
```

# Exercise 10
Find the average profit by order year. 
**Note: You will need to use the aggregate() function to do this. To understand how the function works type ?aggregate in the console.**

```{r}

#
#
#
#
## Create a new data frame from sales containingRow ID, the Order Date and Profit, adding a
# fourth column containing the sales year, extracted from the order date(assigning column
# names on the fly)
profit_subset <- setNames(data.frame(sales$Row.ID, 
                                     sales$Order.Date,
                                     sales$Profit,
                                     lubridate::year(sales$Order.Date)),
                          c("Row.ID","Order.Date","Profit","Order.Year"))
profit_subset[1:8,]

# Aggregate profits by region using mean function, and assign column names
profits_by_year <- setNames(aggregate(profit_subset$Profit,
                                        by=list(profit_subset$Order.Year),
                                        FUN = mean),
                              c("Year","Avg.Profit")) 

# Sort results by Year
profits_by_year <- profits_by_year[order(profits_by_year$Year,
                                             decreasing = FALSE),]
profits_by_year

```